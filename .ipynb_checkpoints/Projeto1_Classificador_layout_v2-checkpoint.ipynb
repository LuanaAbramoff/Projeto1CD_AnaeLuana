{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Ana Almeida Barros\n",
    "\n",
    "Nome: Luana Abramoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo airpods1.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'airpods1.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>eu n√£o sei se faz muito sentido lan√ßar as airt...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>quantidade</td>\n",
       "      <td>porcentagem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@margaridacs10 @filipa_chaan \"comprem os nosso...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RELEVANTE</td>\n",
       "      <td>132</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>apple atualiza airpods pro com suporte a √°udio...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IRRELEVANTE</td>\n",
       "      <td>168</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@karinnesanso miga, xaomi resolvendo minha vid...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>receita federal do aeroporto jfk apreendeu fon...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia  Unnamed: 2  \\\n",
       "0  eu n√£o sei se faz muito sentido lan√ßar as airt...           0         NaN   \n",
       "1  @margaridacs10 @filipa_chaan \"comprem os nosso...           0         NaN   \n",
       "2  apple atualiza airpods pro com suporte a √°udio...           0         NaN   \n",
       "3  @karinnesanso miga, xaomi resolvendo minha vid...           1         NaN   \n",
       "4  receita federal do aeroporto jfk apreendeu fon...           0         NaN   \n",
       "\n",
       "    Unnamed: 3  Unnamed: 4   Unnamed: 5  \n",
       "0          NaN  quantidade  porcentagem  \n",
       "1    RELEVANTE         132           44  \n",
       "2  IRRELEVANTE         168           56  \n",
       "3          NaN         NaN          NaN  \n",
       "4          NaN         NaN          NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nao tiro da cabe√ßa ariana grande de wave e air...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>quantidade</td>\n",
       "      <td>porcentagem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>airpods pro ganham √°udio espacial e troca auto...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RELEVANTE</td>\n",
       "      <td>102</td>\n",
       "      <td>51.7766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>alf√¢ndega dos eua confunde fones da oneplus co...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IRRELEVANTE</td>\n",
       "      <td>95</td>\n",
       "      <td>48.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>putaria do caralho\\ncopyright √© coisa de retar...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@umameira eles n cabem na minha orelhinha :c\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia  Unnamed: 2  \\\n",
       "0  nao tiro da cabe√ßa ariana grande de wave e air...           0         NaN   \n",
       "1  airpods pro ganham √°udio espacial e troca auto...           1         NaN   \n",
       "2  alf√¢ndega dos eua confunde fones da oneplus co...           0         NaN   \n",
       "3  putaria do caralho\\ncopyright √© coisa de retar...           0         NaN   \n",
       "4  @umameira eles n cabem na minha orelhinha :c\\n...           1         NaN   \n",
       "\n",
       "    Unnamed: 3   Unnamed: 4   Unnamed: 5  \n",
       "0          NaN  quantidade   porcentagem  \n",
       "1    RELEVANTE          102      51.7766  \n",
       "2  IRRELEVANTE           95      48.2234  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Os Airpods s√£o fones de ouvido sem fio da Apple. Na classsificacao dos tweets, buscamos observar palavras, expressoes ou emojis que demonstrassem um senso de opiniao, satisfacao ou emocao em relacao ao produto. Alguns casos vistos foram pessoas declarando que queriam muito o produto, dizendo s√£o muito felizes em t√™-lo, fazendo um cr√≠tica negativa a algum aspecto pontual e fazendo comparacoes entre marcas e precos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = '[!-.:?;\\n]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "def cleanup_stopwords(text):\n",
    "    stopwords=['e', 'que','de','um','o', 'a', 'os', 'as', 'no', 'na', 'do', 'da']\n",
    "    for word in stopwords:\n",
    "        text = text.replace(\" \" + word + \" \", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantes=train[train[\"Relev√¢ncia\"]==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_R=\" \".join(relevantes.Treinamento)\n",
    "texto_R=cleanup(texto_R).lower()\n",
    "texto_R=cleanup_stopwords(texto_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@karinnesanso',\n",
       " 'miga',\n",
       " 'xaomi',\n",
       " 'resolvendo',\n",
       " 'minha',\n",
       " 'vida',\n",
       " 'airpods',\n",
       " 'q',\n",
       " 'tenho',\n",
       " 'v√™']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todas_as_palavras_R=texto_R.split()             \n",
    "todas_as_palavras_R[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       @karinnesanso\n",
       "1                miga\n",
       "2               xaomi\n",
       "3          resolvendo\n",
       "4               minha\n",
       "            ...      \n",
       "1828          airpods\n",
       "1829             pode\n",
       "1830               me\n",
       "1831           deixar\n",
       "1832            feliz\n",
       "Length: 1833, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_train_R = pd.Series(todas_as_palavras_R)\n",
    "serie_train_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airpods     130\n",
       "eu           47\n",
       "n√£o          42\n",
       "meu          34\n",
       "com          27\n",
       "           ... \n",
       "or            1\n",
       "aguentam      1\n",
       "sejam         1\n",
       "trocar        1\n",
       "ne            1\n",
       "Length: 862, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_train_R = serie_train_R.value_counts()\n",
    "tabela_train_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airpods     0.070922\n",
       "eu          0.025641\n",
       "n√£o         0.022913\n",
       "meu         0.018549\n",
       "com         0.014730\n",
       "              ...   \n",
       "or          0.000546\n",
       "aguentam    0.000546\n",
       "sejam       0.000546\n",
       "trocar      0.000546\n",
       "ne          0.000546\n",
       "Length: 862, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_train_relativa_R = serie_train_R.value_counts(True)\n",
    "tabela_train_relativa_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevantes=train[train[\"Relev√¢ncia\"]==0]\n",
    "\n",
    "texto_I=\" \".join(irrelevantes.Treinamento) # um unico texto\n",
    "texto_I=cleanup(texto_I).lower()\n",
    "texto_I=cleanup_stopwords(texto_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eu',\n",
       " 'n√£o',\n",
       " 'sei',\n",
       " 'se',\n",
       " 'faz',\n",
       " 'muito',\n",
       " 'sentido',\n",
       " 'lan√ßar',\n",
       " 'airtags',\n",
       " 'e/ou']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todas_as_palavras_I=texto_I.split()             \n",
    "todas_as_palavras_I[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          eu\n",
       "1                         n√£o\n",
       "2                         sei\n",
       "3                          se\n",
       "4                         faz\n",
       "                ...          \n",
       "2361                    piada\n",
       "2362                      por\n",
       "2363                 confus√£o\n",
       "2364                  confira\n",
       "2365    https//tco/bshujc7q68\n",
       "Length: 2366, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_train_I = pd.Series(todas_as_palavras_I)\n",
    "serie_train_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airpods                  154\n",
       "dos                       46\n",
       "oneplus                   43\n",
       "apple                     36\n",
       "com                       35\n",
       "                        ... \n",
       "https//tco/p8ke2k4byh      1\n",
       "consegue                   1\n",
       "brancos                    1\n",
       "comprem                    1\n",
       "apoderouse                 1\n",
       "Length: 1067, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_train_I = serie_train_I.value_counts()\n",
    "tabela_train_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airpods                  0.065089\n",
       "dos                      0.019442\n",
       "oneplus                  0.018174\n",
       "apple                    0.015216\n",
       "com                      0.014793\n",
       "                           ...   \n",
       "https//tco/p8ke2k4byh    0.000423\n",
       "consegue                 0.000423\n",
       "brancos                  0.000423\n",
       "comprem                  0.000423\n",
       "apoderouse               0.000423\n",
       "Length: 1067, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_train_relativa_I = serie_train_I.value_counts(True)\n",
    "tabela_train_relativa_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular a chance de um tweet ser relevante ou nao, utiliza-se as seguintes formulas:\n",
    "\n",
    "$P(R|tweet) = \\frac{P(tweet|R)P(R)}{P(tweet)}$\n",
    "\n",
    "$P(I|tweet) = \\frac{P(tweet|I)P(I)}{P(tweet)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862\n",
      "1067\n",
      "1665\n"
     ]
    }
   ],
   "source": [
    "#definindo quantidade de palavras relevantes, irrelevantes e total\n",
    "todas_as_palavras_R_semrepetir = []\n",
    "\n",
    "for i in todas_as_palavras_R:\n",
    "    if i not in todas_as_palavras_R_semrepetir:\n",
    "        todas_as_palavras_R_semrepetir.append(i)\n",
    "        \n",
    "todas_as_palavras_I_semrepetir = []\n",
    "\n",
    "for i in todas_as_palavras_I:\n",
    "    if i not in todas_as_palavras_I_semrepetir:\n",
    "        todas_as_palavras_I_semrepetir.append(i)\n",
    "\n",
    "\n",
    "interseccao=0\n",
    "for i in todas_as_palavras_R_semrepetir:\n",
    "    if i in todas_as_palavras_I_semrepetir:\n",
    "        interseccao +=1\n",
    "\n",
    "total_ambas = (len(todas_as_palavras_R_semrepetir) + len(todas_as_palavras_I_semrepetir)) - interseccao\n",
    "\n",
    "\n",
    "print(len(todas_as_palavras_R_semrepetir))# quantidade de palavras relevantes\n",
    "print(len(todas_as_palavras_I_semrepetir))# quantidade de palavras irrelevantes\n",
    "print(total_ambas) #quantidade total de palavras(tirando a interseccao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo as probabilidades\n",
    "P_R=0.44 \n",
    "P_I=0.56 #calculadas na pr√≥pria planilha de treinamento do excel\n",
    "\n",
    "#P_tweet nao precisa ser calculada pois ambas ùëÉ(ùëÖ|ùë°ùë§ùëíùëíùë°) e ùëÉ(ùêº|ùë°ùë§ùëíùëíùë°) sao divididas por ela.\n",
    "\n",
    "\n",
    "def probabilidadefraseR(x):\n",
    "    pfrase=1\n",
    "    palavras = x.split()\n",
    "    for e in palavras:\n",
    "        if e not in todas_as_palavras_R_semrepetir:\n",
    "            ppalavra = 1/(len(todas_as_palavras_R_semrepetir) + total_ambas)\n",
    "        else:\n",
    "            ppalavra = (tabela_train_R[e]+ 1)/(len(todas_as_palavras_R_semrepetir) + total_ambas)\n",
    "        pfrase= pfrase*ppalavra\n",
    "    return pfrase\n",
    "\n",
    "def probabilidadefraseI(x):\n",
    "    pfrase=1\n",
    "    palavras = x.split()\n",
    "    for e in palavras:\n",
    "        if e not in todas_as_palavras_I_semrepetir:\n",
    "            ppalavra = 1/(len(todas_as_palavras_I_semrepetir) + total_ambas)\n",
    "        else:\n",
    "            ppalavra = (tabela_train_I[e]+ 1)/(len(todas_as_palavras_I_semrepetir) + total_ambas)\n",
    "        pfrase = pfrase*ppalavra\n",
    "    return pfrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nao tiro da cabe√ßa ariana grande de wave e air...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>quantidade</td>\n",
       "      <td>porcentagem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>airpods pro ganham √°udio espacial e troca auto...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RELEVANTE</td>\n",
       "      <td>102</td>\n",
       "      <td>51.7766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>alf√¢ndega dos eua confunde fones da oneplus co...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IRRELEVANTE</td>\n",
       "      <td>95</td>\n",
       "      <td>48.2234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>putaria do caralho\\ncopyright √© coisa de retar...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@umameira eles n cabem na minha orelhinha :c\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>eu falei mal na sala do airpod da apple pq meu...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>aquele airpod √© 1.000 pila t√° louco eu n√£o pag...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>@analuizatitto amg sim virar cadelinha da appl...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>como q  eu vou tratar quem tem airpod original...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>comprei um fone novo de uma marca que chama ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevancia  \\\n",
       "0    nao tiro da cabe√ßa ariana grande de wave e air...           0   \n",
       "1    airpods pro ganham √°udio espacial e troca auto...           1   \n",
       "2    alf√¢ndega dos eua confunde fones da oneplus co...           0   \n",
       "3    putaria do caralho\\ncopyright √© coisa de retar...           0   \n",
       "4    @umameira eles n cabem na minha orelhinha :c\\n...           1   \n",
       "..                                                 ...         ...   \n",
       "192  eu falei mal na sala do airpod da apple pq meu...           1   \n",
       "193  aquele airpod √© 1.000 pila t√° louco eu n√£o pag...           1   \n",
       "194  @analuizatitto amg sim virar cadelinha da appl...           1   \n",
       "195  como q  eu vou tratar quem tem airpod original...           1   \n",
       "196  comprei um fone novo de uma marca que chama ha...           0   \n",
       "\n",
       "     Unnamed: 2   Unnamed: 3   Unnamed: 4   Unnamed: 5 Classificador  \n",
       "0           NaN          NaN  quantidade   porcentagem             1  \n",
       "1           NaN    RELEVANTE          102      51.7766             0  \n",
       "2           NaN  IRRELEVANTE           95      48.2234             0  \n",
       "3           NaN          NaN          NaN          NaN             1  \n",
       "4           NaN          NaN          NaN          NaN             1  \n",
       "..          ...          ...          ...          ...           ...  \n",
       "192         NaN          NaN          NaN          NaN             1  \n",
       "193         NaN          NaN          NaN          NaN             1  \n",
       "194         NaN          NaN          NaN          NaN             1  \n",
       "195         NaN          NaN          NaN          NaN             0  \n",
       "196         NaN          NaN          NaN          NaN             0  \n",
       "\n",
       "[197 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "for j in test.Teste:\n",
    "    tweet = j\n",
    "    j=cleanup(str(j)).lower()\n",
    "    j=cleanup_stopwords(j)\n",
    "    \n",
    "    P_tweet_R =probabilidadefraseR(j)\n",
    "    P_R_tweet=P_tweet_R*P_R\n",
    "\n",
    "    P_tweet_I = probabilidadefraseI(j)\n",
    "    P_I_tweet = P_tweet_I*P_I\n",
    "    \n",
    "    \n",
    "    if (P_R_tweet> P_I_tweet):\n",
    "        test.loc[test.Teste==tweet, \"Classificador\"] = \"1\"\n",
    "    else:\n",
    "        test.loc[test.Teste==tweet, \"Classificador\"] = \"0\" \n",
    "test\n",
    "#Observar coluna Classificador!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.329949</td>\n",
       "      <td>0.152284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.162437</td>\n",
       "      <td>0.355330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador         0         1\n",
       "Relevancia                       \n",
       "0              0.329949  0.152284\n",
       "1              0.162437  0.355330"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Relevancia,test.Classificador,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance antes da utilizacao da funcao cleanup_stopwords:\n",
    "\n",
    "38% era irrelevante e foi classificado irrelevante. 29% era relevante e foi classificado relevante. Assim, 67% dos resultados foram avaliados corretamente.\n",
    "\n",
    "10% era irrelevante e foi considerado relevante. 21% era relevante e foi considerado irrelevante. Assim 31% dos resultados foram avaliados erroneamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance depois da utilizacao da funcao cleanup_stopwords:\n",
    "\n",
    "32% era irrelevante e foi classificado irrelevante. 35% era relevante e foi classificado relevante. Assim, 67% dos resultados foram avaliados corretamente.\n",
    "\n",
    "15% era irrelevante e foi considerado relevante. 16% era relevante e foi considerado irrelevante. Assim 31% dos resultados foram avaliados erroneamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre o uso da funcao de limpeza cleanup_stopwords: Nosso intuito com essa funcao era de retirar dos tweets palavras de uso excessivo e sem grande relevancia para a analise(ex: e, a, de, que ...). Assim, o classificador poderia focar mais nas outras palavras. No final, n√£o houve grande diferenca na performance, pois houve a mesma porcentagem de acerto, mas mesmo assim, foi um construcao positiva.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre a interpretacao das mensagens com dupla nega√ß√£o e sarcasmo: Como os tweets podem ser classificados apenas como irrelevantes ou relevantes, √© prov√°vel que as afirmacoes de sarcasmo, mesmo utilizando palavras positivas com sentido negativo,√© prov√°vel que tenham sido alocados corretamento como relevantes. Contudo, se tiv√©ssemos criado categorias de relevantes positivas e negativas, o classificador n√£o teria a habilidade de identificar esse tipo de mensagem como negativa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets: Ao pegar novos tweets e aplicar neles o classificador, nao faria sentido treinar o classificador com esses mesmos tweets, visto que eles receberiam a mesma classificacao que receberam em primeiro lugar, ja que o classificador opera com as mesmas regras que antes. Assim, a taxa de sucesso nessa tentativa seria de 100%, mas isso n√£o indicaria funcionamento ideal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar: Usando o artigo \"A practical explanation of a Naive Bayes classifier\", da p√°gina Monkey Learn, entendemos que a estrat√©gia Lemmatizing poderia ser interesante para uma melhoria do classificador. Com essa estrat√©gia, agrupa-se variantes de uma mesma palavra como uma s√≥. Assim, se esse grupo de palavras for de fato, por exemplo, relevante, aumentamos a chance de cada palavra do grupo ser classificada como relevante (pois o grupo se torna mais forte com a ocorrencia de varias palavras dele). Se nao tivesse esse agrupamento, uma palavra dessa familia poderia acabar sendo classificada como irrelevante pois por acaso apareceram mais vezes dela em especifico nas irrelevantes. Como fazer isso: a mao mesmo, com pesquisa para determinar as varias palavras que pertencem a uma mesma raiz ou com uma outra ferramenta que aprende sozinha baseada em uma base de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
